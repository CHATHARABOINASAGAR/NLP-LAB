{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMitkNgo6X6r2DLn/1C7DGI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CHATHARABOINASAGAR/NLP-LAB/blob/main/NLB_AS_22_08_2K25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/train.csv')\n",
        "\n",
        "# Show column names to confirm the correct one\n",
        "print(\"Available columns:\", df.columns.tolist())\n",
        "\n",
        "# Use the correct column name (replace 'description_x' if different)\n",
        "column_name = 'description_x'\n",
        "if column_name not in df.columns:\n",
        "    # Fallback: try common text column names\n",
        "    for alt in ['description', 'text', 'tweet', 'content']:\n",
        "        if alt in df.columns:\n",
        "            column_name = alt\n",
        "            break\n",
        "    else:\n",
        "        raise KeyError(\"No suitable text column found in dataset.\")\n",
        "\n",
        "# Load the spaCy model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Get the first 5 text entries\n",
        "sample_texts = df[column_name].dropna().head().tolist()\n",
        "\n",
        "# Process each text entry\n",
        "for i, text in enumerate(sample_texts):\n",
        "    print(f\"\\n--- Sentence {i+1}: '{text}' ---\")\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Prepare lists to hold the parts of speech\n",
        "    nouns = []\n",
        "    verbs = []\n",
        "    adjectives = []\n",
        "\n",
        "    print(f\"{'Token':<20} {'POS Tag':<10} {'Dependency':<15}\")\n",
        "    print(\"-\" * 45)\n",
        "\n",
        "    # Extract and print token details\n",
        "    for token in doc:\n",
        "        print(f\"{token.text:<20} {token.pos_:<10} {token.dep_:<15}\")\n",
        "        if token.pos_ == 'NOUN':\n",
        "            nouns.append(token.text)\n",
        "        elif token.pos_ == 'VERB':\n",
        "            verbs.append(token.text)\n",
        "        elif token.pos_ == 'ADJ':\n",
        "            adjectives.append(token.text)\n",
        "\n",
        "    # Print the extracted parts of speech\n",
        "    print(\"\\nNouns:\", nouns)\n",
        "    print(\"Verbs:\", verbs)\n",
        "    print(\"Adjectives:\", adjectives)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjkL0ffuSKmC",
        "outputId": "3f3a6687-49e4-40b1-de63-6bc468004936"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available columns: ['id', 'keyword', 'location', 'text', 'target']\n",
            "\n",
            "--- Sentence 1: 'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all' ---\n",
            "Token                POS Tag    Dependency     \n",
            "---------------------------------------------\n",
            "Our                  PRON       poss           \n",
            "Deeds                NOUN       nsubj          \n",
            "are                  AUX        ccomp          \n",
            "the                  DET        det            \n",
            "Reason               PROPN      attr           \n",
            "of                   ADP        prep           \n",
            "this                 DET        det            \n",
            "#                    SYM        nmod           \n",
            "earthquake           NOUN       pobj           \n",
            "May                  AUX        aux            \n",
            "ALLAH                PROPN      nsubj          \n",
            "Forgive              VERB       ROOT           \n",
            "us                   PRON       dobj           \n",
            "all                  PRON       dobj           \n",
            "\n",
            "Nouns: ['Deeds', 'earthquake']\n",
            "Verbs: ['Forgive']\n",
            "Adjectives: []\n",
            "\n",
            "--- Sentence 2: 'Forest fire near La Ronge Sask. Canada' ---\n",
            "Token                POS Tag    Dependency     \n",
            "---------------------------------------------\n",
            "Forest               NOUN       compound       \n",
            "fire                 NOUN       ROOT           \n",
            "near                 ADP        prep           \n",
            "La                   PROPN      compound       \n",
            "Ronge                PROPN      compound       \n",
            "Sask                 PROPN      pobj           \n",
            ".                    PUNCT      punct          \n",
            "Canada               PROPN      ROOT           \n",
            "\n",
            "Nouns: ['Forest', 'fire']\n",
            "Verbs: []\n",
            "Adjectives: []\n",
            "\n",
            "--- Sentence 3: 'All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected' ---\n",
            "Token                POS Tag    Dependency     \n",
            "---------------------------------------------\n",
            "All                  DET        det            \n",
            "residents            NOUN       nsubj          \n",
            "asked                VERB       ROOT           \n",
            "to                   PART       aux            \n",
            "'                    PUNCT      punct          \n",
            "shelter              VERB       xcomp          \n",
            "in                   ADP        prep           \n",
            "place                NOUN       pobj           \n",
            "'                    PUNCT      punct          \n",
            "are                  AUX        aux            \n",
            "being                AUX        auxpass        \n",
            "notified             VERB       ccomp          \n",
            "by                   ADP        agent          \n",
            "officers             NOUN       pobj           \n",
            ".                    PUNCT      punct          \n",
            "No                   DET        det            \n",
            "other                ADJ        amod           \n",
            "evacuation           NOUN       nsubjpass      \n",
            "or                   CCONJ      cc             \n",
            "shelter              NOUN       conj           \n",
            "in                   ADP        prep           \n",
            "place                NOUN       compound       \n",
            "orders               NOUN       pobj           \n",
            "are                  AUX        auxpass        \n",
            "expected             VERB       ROOT           \n",
            "\n",
            "Nouns: ['residents', 'place', 'officers', 'evacuation', 'shelter', 'place', 'orders']\n",
            "Verbs: ['asked', 'shelter', 'notified', 'expected']\n",
            "Adjectives: ['other']\n",
            "\n",
            "--- Sentence 4: '13,000 people receive #wildfires evacuation orders in California ' ---\n",
            "Token                POS Tag    Dependency     \n",
            "---------------------------------------------\n",
            "13,000               NUM        nummod         \n",
            "people               NOUN       nsubj          \n",
            "receive              VERB       ROOT           \n",
            "#                    SYM        det            \n",
            "wildfires            NOUN       compound       \n",
            "evacuation           NOUN       compound       \n",
            "orders               NOUN       dobj           \n",
            "in                   ADP        prep           \n",
            "California           PROPN      pobj           \n",
            "\n",
            "Nouns: ['people', 'wildfires', 'evacuation', 'orders']\n",
            "Verbs: ['receive']\n",
            "Adjectives: []\n",
            "\n",
            "--- Sentence 5: 'Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school ' ---\n",
            "Token                POS Tag    Dependency     \n",
            "---------------------------------------------\n",
            "Just                 ADV        advmod         \n",
            "got                  AUX        auxpass        \n",
            "sent                 VERB       ROOT           \n",
            "this                 DET        det            \n",
            "photo                NOUN       dobj           \n",
            "from                 ADP        prep           \n",
            "Ruby                 PROPN      nmod           \n",
            "#                    SYM        nmod           \n",
            "Alaska               PROPN      pobj           \n",
            "as                   SCONJ      mark           \n",
            "smoke                NOUN       nsubj          \n",
            "from                 ADP        prep           \n",
            "#                    SYM        det            \n",
            "wildfires            NOUN       pobj           \n",
            "pours                VERB       advcl          \n",
            "into                 ADP        prep           \n",
            "a                    DET        det            \n",
            "school               NOUN       pobj           \n",
            "\n",
            "Nouns: ['photo', 'smoke', 'wildfires', 'school']\n",
            "Verbs: ['sent', 'pours']\n",
            "Adjectives: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "b2p77IRASZ8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# The list of sentences from your question\n",
        "texts = [\n",
        "    \"My phone number is 1234567890 and my email is test@domain.com\",\n",
        "    \"Visit https://example.com for more info!!!\",\n",
        "    \"HELLO!!! This is SOOOOO exciting :))\",\n",
        "    \"Contact us at info@company.org or call +91 98765-43210\",\n",
        "    \"Python's regex is very useful!!!  #Coding #Fun\"\n",
        "]\n",
        "\n",
        "## 1. Find Phone Numbers\n",
        "print(\"--- Found Phone Numbers ---\")\n",
        "\n",
        "# Regex to find different phone number formats present in the text\n",
        "phone_pattern = r'(?:\\+\\d{1,3}[-\\s]?)?\\d{10}|(?:\\+\\d{1,3}[-\\s]?)?\\d{5}[-\\s]?\\d{5}'\n",
        "found_phones = []\n",
        "\n",
        "# Loop through each text to find phone numbers\n",
        "for text in texts:\n",
        "    found_phones.extend(re.findall(phone_pattern, text))\n",
        "\n",
        "# Print the results\n",
        "if found_phones:\n",
        "    for phone in found_phones:\n",
        "        print(phone)\n",
        "else:\n",
        "    print(\"No phone numbers were found.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*40 + \"\\n\") # Separator for clarity\n",
        "\n",
        "## 2. Remove Phone Numbers, Emails, URLs, and Special Characters\n",
        "print(\"--- Cleaned Text ---\")\n",
        "\n",
        "cleaned_texts = []\n",
        "for text in texts:\n",
        "    # Make a copy to modify\n",
        "    clean_text = text\n",
        "\n",
        "    # Remove URLs (e.g., https://example.com)\n",
        "    clean_text = re.sub(r'https?://\\S+', '', clean_text)\n",
        "\n",
        "    # Remove emails (e.g., test@domain.com)\n",
        "    clean_text = re.sub(r'\\S+@\\S+\\.\\S+', '', clean_text)\n",
        "\n",
        "    # Remove phone numbers using the same pattern as above\n",
        "    clean_text = re.sub(phone_pattern, '', clean_text)\n",
        "\n",
        "    # Remove special characters (anything not a letter, number, or space)\n",
        "    clean_text = re.sub(r'[^a-zA-Z0-9\\s]', '', clean_text)\n",
        "\n",
        "    # Remove extra whitespace (like double spaces) that may result from removal\n",
        "    clean_text = ' '.join(clean_text.split())\n",
        "\n",
        "    cleaned_texts.append(clean_text)\n",
        "\n",
        "# Print the original vs. cleaned text for comparison\n",
        "for i in range(len(texts)):\n",
        "    print(f\"Original: \\\"{texts[i]}\\\"\")\n",
        "    print(f\"Cleaned:  \\\"{cleaned_texts[i]}\\\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmpKZ-VuSlLR",
        "outputId": "d8d84615-bdd7-462f-e4c0-62c41b4a9d27"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Found Phone Numbers ---\n",
            "1234567890\n",
            "+91 98765-43210\n",
            "\n",
            "========================================\n",
            "\n",
            "--- Cleaned Text ---\n",
            "Original: \"My phone number is 1234567890 and my email is test@domain.com\"\n",
            "Cleaned:  \"My phone number is and my email is\"\n",
            "\n",
            "Original: \"Visit https://example.com for more info!!!\"\n",
            "Cleaned:  \"Visit for more info\"\n",
            "\n",
            "Original: \"HELLO!!! This is SOOOOO exciting :))\"\n",
            "Cleaned:  \"HELLO This is SOOOOO exciting\"\n",
            "\n",
            "Original: \"Contact us at info@company.org or call +91 98765-43210\"\n",
            "Cleaned:  \"Contact us at or call\"\n",
            "\n",
            "Original: \"Python's regex is very useful!!!  #Coding #Fun\"\n",
            "Cleaned:  \"Pythons regex is very useful Coding Fun\"\n",
            "\n"
          ]
        }
      ]
    }
  ]
}